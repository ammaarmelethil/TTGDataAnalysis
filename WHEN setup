#SQL database into pandas dataframes
from sqlalchemy import create_engine
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
from datetime import datetime
import math
import numpy as np
from sklearn.linear_model import Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
import re #for SPX cleaning. Some dates were snuck in there. Will replace with previous valid value


def TimeToDate(timestamps):
    datetime_objects = [datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S') for timestamp in timestamps]
    dates = [dt.strftime('%Y-%m-%d') for dt in datetime_objects]
    return dates


server='192.168.50.221'
database='CapUOC_DataAnalysis'
username='clong'
password='KimJongUn2002'

# Replace 'username', 'password', 'hostname', 'database_name' with your SQL Server credentials
connection_string = 'mssql+pyodbc://clong:KimJongUn2002@192.168.50.221/CapUOC_DataAnalysis?driver=ODBC+Driver+17+for+SQL+Server'

# Create SQLAlchemy engine
engine = create_engine(connection_string)
t=datetime.now()
# Execute a SQL query and load the results into a DataFrame
query1 ='SELECT * FROM Trades ORDER BY [When]'
DF=pd.read_sql(query1, engine)
query3='SELECT BarDateTime, [Open], High, Low, [Close] FROM Template_HistoData WHERE (BarDateTime > \'2022 - 05 - 27 08:00:00.000\') and (BarDateTime < \'2023 - 12 - 29 23:00:00.000\') ORDER BY BarDateTime'
df3=pd.read_sql(query3, engine)
print(datetime.now()-t)
# Close the connection
engine.dispose()

df3['When']=df3['BarDateTime']
df3=df3.drop(columns='BarDateTime')
df3=df3.When.drop_duplicates()
print(datetime.now())

times = []
for time in DF['When']:
    times.append(str(time))

Dates = TimeToDate(times)
DF['Date'] = Dates


DF['SPX'] = DF[' SPX ']
DF['NDX'] = DF[' NDX ']
DF = DF.drop(columns=[' SPX ', ' NDX '])

 # Filter out rows where 'Side' is not NaN because rate data goes back a while

sides=[]
for i in DF.Side:
    sides.append(i)
adjsides=[]
for i in sides:
    if i =='A  ':
        adjsides.append('A')
    elif i =='B  ':
        adjsides.append('B')
DF=DF.drop(columns='Side')
DF['Side']=adjsides
    

    
mktvars=['VIX','NDX'] #Easy stuff to work with
for var in mktvars:
    mktvarcleaning = []
    for value in DF[var]:
        mktvarcleaning.append(value)

    for i in range(len(mktvarcleaning)):
        if mktvarcleaning[i] == '#VALUE!':
            mktvarcleaning[i] = mktvarcleaning[i - 1]

    newmktvar = []
    for i in mktvarcleaning:
        newmktvar.append(float(i))
    DF=DF.drop(columns=var)
    DF[var]=newmktvar

NP=[]
for i in DF['Profit_Net']:
    NP.append(i)
for i in NP:
    if i =='#DIV/0!':
        NP[NP.index(i)]=float(0.0)
    else:
        NP[NP.index(i)]=float(i)
DF['Net Profit']=NP
DF=DF.drop(columns='Profit_Net')
        

regex=re.compile(r'\d\d[/]\d\d[/]\d\d\d\d') #SPX cleaning was weird because some dates were mixed in with the sample data. Had to get its own section outside of loop. 
SPX=[]
for value in DF['SPX']:
    SPX.append(value)
dateissues=[]
SPXcleaning=[]
for value in SPX:
    if regex.search(value):
        dateissues.append(value)
for issue in dateissues:
    SPX[SPX.index(issue)]=SPX[SPX.index(issue)-1]
SPXcleaning=SPX
for i in range(len(SPXcleaning)):
    if SPXcleaning[i]=='#VALUE!':
        SPXcleaning[i]=SPXcleaning[i-1]
newSPX=[]      
for i in SPXcleaning:
    newSPX.append(float(i))
DF.drop(columns='SPX')
DF['SPX']=newSPX

SPYcleaning=[] #SPY had a few hundred missing values as opposed to less that 10. I converted using SPX values to get a clearer picture. A spread will have to be implemented in this calculation for further accuracy
SPXstuff=[]
for value in DF['SPY']:
    SPYcleaning.append(value)
for value in DF['SPX']:
    SPXstuff.append(value)
newSPY=[]
for value in SPYcleaning:
    if value!='#VALUE!':
        newSPY.append(value)
    else:
        newSPY.append(float((float(SPXstuff[SPYcleaning.index(value)])/10)))
DF=DF.drop(columns='SPY')
#float commands werent working so had to hard list it
SPY=[]
for string in newSPY:
    SPY.append(float(string))
DF['SPY']=SPY




DF=DF.merge(df3, on='When', how='outer')
times = []
for time in DF['When']:
    times.append(str(time))

Dates = TimeToDate(times)
DF['DATE'] = Dates
DF=DF.drop(columns='Date')
DF.fillna(float(0))
    
Trade=[]
trades=[]
for i in DF.Side:
    trades.append(i)
    
for i in trades:
    if i=='A' or i=='B':
        Trade.append(1)
    else:
        Trade.append(0)

DF['Trade']=Trade
DF=DF.sort_values('When')
print(DF)
print('The data frame is ready for "when" analysis')
